# ===== Core =====
ClusterName={{ cluster_name | default('hybrid_cluster') }}
# These must match the master's hostname
SlurmctldHost={{ slurm_control_host }}
ControlMachine={{ slurm_control_host }}

# Force IPv4 to avoid AF_UNSPEC/IPv6 surprises
CommunicationParameters=IPv4

# Bind controller to master's IPv4 address
ControlAddr={{ hostvars[slurm_control_host].ansible_host
               | default(hostvars[slurm_control_host].ansible_default_ipv4.address) }}

# Ports
SlurmctldPort=6817
SlurmdPort=6818

# Auth/log/state
AuthType=auth/munge
SlurmUser=slurm
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmdPidFile=/var/run/slurmd.pid
SlurmctldLogFile={{ slurm_log_dir }}/slurmctld.log
SlurmdLogFile={{ slurm_log_dir }}/slurmd.log
StateSaveLocation={{ slurm_state_dir }}

# Sched/Select
SchedulerType=sched/backfill
SelectType=select/cons_tres
SelectTypeParameters=CR_Core

# Timeouts
ReturnToService=1
SlurmctldTimeout=120
SlurmdTimeout=300
KillWait=30
MinJobAge=300

# ===== Nodes =====
# Master participates as a compute node (Option B)
NodeName={{ slurm_control_host }} \
  NodeHostname={{ slurm_control_host }} \
  NodeAddr={{ hostvars[slurm_control_host].ansible_host
              | default(hostvars[slurm_control_host].ansible_default_ipv4.address) }} \
  CPUs={{ hostvars[slurm_control_host].ansible_facts['processor_vcpus'] | default(4) }} \
  RealMemory={{ (hostvars[slurm_control_host].ansible_facts['memtotal_mb'] | default(8192)) | int }} \
  State=UNKNOWN

# Workers
{% for host in groups['slurm_workers'] %}
NodeName={{ host }} \
  NodeHostname={{ host }} \
  NodeAddr={{ hostvars[host].ansible_host
              | default(hostvars[host].ansible_default_ipv4.address) }} \
  CPUs={{ hostvars[host].ansible_facts['processor_vcpus'] | default(4) }} \
  RealMemory={{ (hostvars[host].ansible_facts['memtotal_mb'] | default(8192)) | int }} \
  State=UNKNOWN
{% endfor %}

# Dummy partition to avoid empty config edge cases
PartitionName=invalid Nodes=NONE Default=NO MaxTime=INFINITE State=UP

# Real partitions (include master too)
{% for p in slurm_partitions %}
PartitionName={{ p.name }} Nodes={{ p.nodes }},{{ slurm_control_host }} Default={{ 'YES' if p.default else 'NO' }} MaxTime={{ p.maxtime }} State=UP
{% endfor %}

# Accounting (off for now)
AccountingStorageType=accounting_storage/none
JobCompType=jobcomp/none
